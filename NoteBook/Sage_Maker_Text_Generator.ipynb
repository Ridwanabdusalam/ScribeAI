{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkHT0M6cx6KO"
      },
      "source": [
        "## Connecting to S3 Bucket "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gp3-5NDGxvzP"
      },
      "outputs": [],
      "source": [
        "# codes for s3 retrieval\n",
        "# import boto3\n",
        "# import io\n",
        "# bucket = 'textgenerationbucket'\n",
        "# key = 'text_data/Reviews.csv'\n",
        "# s3_client = boto3.client('s3')\n",
        "# obj = s3_client.get_object(Bucket=bucket, Key=key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "aEIFMiXO3pFt"
      },
      "outputs": [],
      "source": [
        "# Importing Nessesary Packages:\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNINU9p76TW2"
      },
      "source": [
        "## Reading The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nUDOd7Kn3ygV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "1                     0                       0      1  1346976000   \n",
              "2                     1                       1      4  1219017600   \n",
              "3                     3                       3      2  1307923200   \n",
              "4                     0                       0      5  1350777600   \n",
              "\n",
              "                 Summary                                               Text  \n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
              "4            Great taffy  Great taffy at a great price.  There was a wid...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reading the Data:\n",
        "\n",
        "df = pd.read_csv('../Input/Reviews.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LfcTgb3E6BIV"
      },
      "outputs": [],
      "source": [
        "data = df[['Text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eK2INtuD33N8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vithi\\AppData\\Local\\Temp\\ipykernel_141964\\1843601378.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[\"Text\"] = [re.sub(\"[^a-z' ]\", \"\", i.lower()) for i in data[\"Text\"]]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i have bought several of the vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>if you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great taffy at a great price  there was a wide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>great for sesame chickenthis is a good if not ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>i'm disappointed with the flavor the chocolate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>these stars are small so you can give  of thos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>these are the best treats for training and rew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>i am very satisfied product is as advertised i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>568454 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Text\n",
              "0       i have bought several of the vitality canned d...\n",
              "1       product arrived labeled as jumbo salted peanut...\n",
              "2       this is a confection that has been around a fe...\n",
              "3       if you are looking for the secret ingredient i...\n",
              "4       great taffy at a great price  there was a wide...\n",
              "...                                                   ...\n",
              "568449  great for sesame chickenthis is a good if not ...\n",
              "568450  i'm disappointed with the flavor the chocolate...\n",
              "568451  these stars are small so you can give  of thos...\n",
              "568452  these are the best treats for training and rew...\n",
              "568453  i am very satisfied product is as advertised i...\n",
              "\n",
              "[568454 rows x 1 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Making all the words to lower case:\n",
        "\n",
        "data[\"Text\"] = [re.sub(\"[^a-z' ]\", \"\", i.lower()) for i in data[\"Text\"]]\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EXYL0UOw4CyA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than  most'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Printing a sample:\n",
        "\n",
        "data[\"Text\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0rIa8hn6aVB"
      },
      "source": [
        "## Creating the Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U6UNp8FT4FWo"
      },
      "outputs": [],
      "source": [
        "# Function to create a sequence of length 10 Tokens:\n",
        "def create_seq(text, seq_len = 10):\n",
        "    \n",
        "    sequences = []\n",
        "    \n",
        "    #if the number of tokens in text is greater than 5\n",
        "    if len(text.split()) > seq_len:\n",
        "        for i in range(seq_len, len(text.split())):\n",
        "            # Select sequence of tokens\n",
        "            seq = text.split()[i-seq_len:i+1]\n",
        "            #add to the list\n",
        "            sequences.append(\" \".join(seq))\n",
        "        return sequences\n",
        "    else:\n",
        "        return[text]\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c_swT1IA4JN9"
      },
      "outputs": [],
      "source": [
        "sentence =\"i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meatand it smells better my labrador is finicky and she appreciates this product better than most.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Bt3I1hQR4K2M"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i have bought several of the vitality canned dog food products',\n",
              " 'have bought several of the vitality canned dog food products and',\n",
              " 'bought several of the vitality canned dog food products and have',\n",
              " 'several of the vitality canned dog food products and have found',\n",
              " 'of the vitality canned dog food products and have found them',\n",
              " 'the vitality canned dog food products and have found them all',\n",
              " 'vitality canned dog food products and have found them all to',\n",
              " 'canned dog food products and have found them all to be',\n",
              " 'dog food products and have found them all to be of',\n",
              " 'food products and have found them all to be of good',\n",
              " 'products and have found them all to be of good quality',\n",
              " 'and have found them all to be of good quality the',\n",
              " 'have found them all to be of good quality the product',\n",
              " 'found them all to be of good quality the product looks',\n",
              " 'them all to be of good quality the product looks more',\n",
              " 'all to be of good quality the product looks more like',\n",
              " 'to be of good quality the product looks more like a',\n",
              " 'be of good quality the product looks more like a stew',\n",
              " 'of good quality the product looks more like a stew than',\n",
              " 'good quality the product looks more like a stew than a',\n",
              " 'quality the product looks more like a stew than a processed',\n",
              " 'the product looks more like a stew than a processed meatand',\n",
              " 'product looks more like a stew than a processed meatand it',\n",
              " 'looks more like a stew than a processed meatand it smells',\n",
              " 'more like a stew than a processed meatand it smells better',\n",
              " 'like a stew than a processed meatand it smells better my',\n",
              " 'a stew than a processed meatand it smells better my labrador',\n",
              " 'stew than a processed meatand it smells better my labrador is',\n",
              " 'than a processed meatand it smells better my labrador is finicky',\n",
              " 'a processed meatand it smells better my labrador is finicky and',\n",
              " 'processed meatand it smells better my labrador is finicky and she',\n",
              " 'meatand it smells better my labrador is finicky and she appreciates',\n",
              " 'it smells better my labrador is finicky and she appreciates this',\n",
              " 'smells better my labrador is finicky and she appreciates this product',\n",
              " 'better my labrador is finicky and she appreciates this product better',\n",
              " 'my labrador is finicky and she appreciates this product better than',\n",
              " 'labrador is finicky and she appreciates this product better than most.']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "create_seq(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zhRHQMvN4PGg"
      },
      "outputs": [],
      "source": [
        "# Creating a list of text:\n",
        "\n",
        "seq = []\n",
        "text = data[\"Text\"].values\n",
        "for i in range(10000):\n",
        "    seqi = create_seq(text[i])\n",
        "    seq.extend([s for s in seqi if len(s.split(\" \")) == 11])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JnVCecbK4S1V"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "652591"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3tOYjZWz4U14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "one of the more expensive places target has the best price\n",
            "of the more expensive places target has the best price so\n",
            "the more expensive places target has the best price so for\n",
            "more expensive places target has the best price so for now\n",
            "expensive places target has the best price so for now it\n",
            "places target has the best price so for now it works\n",
            "target has the best price so for now it works and\n",
            "has the best price so for now it works and i\n",
            "the best price so for now it works and i recommend\n",
            "best price so for now it works and i recommend it\n"
          ]
        }
      ],
      "source": [
        "for i in range(652581,652591):\n",
        "    print(seq[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "egf5xnFH4Wwa"
      },
      "outputs": [],
      "source": [
        "# create inputs and targets (x and y)\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for s in seq:\n",
        "      if len(s.split()) == 11:\n",
        "        x.append(\" \".join(s.split()[:-1]))\n",
        "        y.append(\" \".join(s.split()[1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XAyB1LKX4YrM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "one of the more expensive places target has the best\n",
            "of the more expensive places target has the best price\n",
            "the more expensive places target has the best price so\n",
            "more expensive places target has the best price so for\n",
            "expensive places target has the best price so for now\n",
            "places target has the best price so for now it\n",
            "target has the best price so for now it works\n",
            "has the best price so for now it works and\n",
            "the best price so for now it works and i\n",
            "best price so for now it works and i recommend\n"
          ]
        }
      ],
      "source": [
        "# Printing Last 5 Texts of  x:\n",
        "\n",
        "for i in range(652581,652591):\n",
        "    print(x[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TAggwH8s4azb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "of the more expensive places target has the best price\n",
            "the more expensive places target has the best price so\n",
            "more expensive places target has the best price so for\n",
            "expensive places target has the best price so for now\n",
            "places target has the best price so for now it\n",
            "target has the best price so for now it works\n",
            "has the best price so for now it works and\n",
            "the best price so for now it works and i\n",
            "best price so for now it works and i recommend\n",
            "price so for now it works and i recommend it\n"
          ]
        }
      ],
      "source": [
        "#Printing Last 5 Texts of y:\n",
        "\n",
        "for i in range(652581,652591):\n",
        "    print(y[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ffMWcurx4cuO"
      },
      "outputs": [],
      "source": [
        "# create integer-to-token mapping\n",
        "int2token = {}\n",
        "cnt = 0\n",
        "\n",
        "for w in set(\" \".join(seq).split()):\n",
        "    int2token[cnt] = w\n",
        "    cnt+= 1\n",
        "\n",
        "# create token-to-integer mapping\n",
        "token2int = {t: i for i, t in int2token.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pcB7qc3d4eht"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9669\n",
            "mush\n"
          ]
        }
      ],
      "source": [
        "#Creating 2 dictionary that maps token\n",
        "\n",
        "print(token2int[\"the\"]) # Token-to-Integer\n",
        "\n",
        "print(int2token[7171])  # Integer-to-Token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77PqC6zi6lLW"
      },
      "source": [
        "## Saving the Dictionary as Json File to s3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6q5ae1br4gpW"
      },
      "outputs": [],
      "source": [
        "# import json \n",
        "# dict1 = token2int\n",
        "# dict2 = int2token\n",
        "# s3 = boto3.resource('s3') \n",
        "# obj1 = s3.Object('textgenerationbucket','inputs/token2int.json')\n",
        "# obj = s3.Object('textgenerationbucket','inputs/int2token.json') \n",
        "# obj1.put(Body=json.dumps(dict1))\n",
        "# obj.put(Body=json.dumps(dict2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "X1XWdI1B4kRa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24301"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set vocabulary size\n",
        "vocab_size = len(int2token)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_integer_seq(word):\n",
        "    temp = []\n",
        "    for w in word.split():\n",
        "        temp.append(token2int[w])\n",
        "\n",
        "    return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LH1dhYyD4oAo"
      },
      "outputs": [],
      "source": [
        "# converting text sequences to integer sequences:\n",
        "\n",
        "x_int = [get_integer_seq(i) for i in x]\n",
        "y_int = [get_integer_seq(i) for i in y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dS9NYGcO4ph4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(652591, 10)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(x_int).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nMOPdvX6t6D"
      },
      "source": [
        "## Saving the processed Input to S3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-ZPdJVBH4r2y"
      },
      "outputs": [],
      "source": [
        "upload_dir = 'inputs/'\n",
        "if not os.path.exists(upload_dir): # Make sure that the folder exists\n",
        "    os.makedirs(upload_dir)\n",
        "\n",
        "np.save(os.path.join(upload_dir, 'y_int.npy'), y_int)\n",
        "np.save(os.path.join(upload_dir, 'x_int.npy'), x_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "L3COOcjZ46zq"
      },
      "outputs": [],
      "source": [
        "# convert lists to numpy arrays\n",
        "x_int = torch.tensor(np.array(x_int))\n",
        "y_int = torch.tensor(np.array(y_int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "5YJYCcqs5UjZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10074, 17397, 24262,  3372,  1252,  9669,  1463,  1988,  5382, 15097],\n",
              "       dtype=torch.int32)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_int[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkJa9Jwn63m5"
      },
      "source": [
        "## Defining the Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0u4TAQm3msFm"
      },
      "outputs": [],
      "source": [
        "class WordLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_hidden=128, n_layers=4, drop_prob=0.3, lr=0.001):\n",
        "        super().__init__()\n",
        "\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "        \n",
        "        self.emb_layer = nn.Embedding(vocab_size, 100)\n",
        "\n",
        "        ## define the LSTM\n",
        "        self.lstm = nn.LSTM(100, n_hidden, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        ## define a dropout layer\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        \n",
        "        ## define the fully-connected layer\n",
        "        self.fc = nn.Linear(n_hidden, vocab_size)      \n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        ''' Forward pass through the network. \n",
        "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
        "\n",
        "        ## pass input through embedding layer\n",
        "        embedded = self.emb_layer(x)     \n",
        "        \n",
        "        ## Get the outputs and the new hidden state from the lstm\n",
        "        lstm_output, hidden = self.lstm(embedded, hidden)\n",
        "        \n",
        "        ## pass through a dropout layer\n",
        "        out = self.dropout(lstm_output)\n",
        "        \n",
        "        #out = out.contiguous().view(-1, self.n_hidden) \n",
        "        out = out.reshape(-1, self.n_hidden) \n",
        "\n",
        "        ## put \"out\" through the fully-connected layer\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # return the final output and the hidden state\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        # if GPU is available\n",
        "        if (torch.cuda.is_available()):\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        \n",
        "        # if GPU is not available\n",
        "        else:\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kODPfdQr6-dN"
      },
      "source": [
        "# Making the Model Use GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "c4qSWHUm5cbY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WordLSTM(\n",
            "  (emb_layer): Embedding(24301, 100)\n",
            "  (lstm): LSTM(100, 128, num_layers=4, batch_first=True, dropout=0.3)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=24301, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "net = WordLSTM()\n",
        "\n",
        "# push the model to GPU (avoid it if you are not using the GPU)\n",
        "# net.cuda()\n",
        "\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOo-Rv1x7I1O"
      },
      "source": [
        "##  Function to Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "aqWK4wrjm8sp"
      },
      "outputs": [],
      "source": [
        "def train(net, epochs=10, batch_size=32, lr=0.001, clip=1, print_every=32):\n",
        "    \n",
        "    # optimizer\n",
        "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    \n",
        "    # loss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # push model to GPU\n",
        "    # net.cuda()\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    for e in range(epochs):\n",
        "\n",
        "        # initialize hidden state\n",
        "        h = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in get_batches(x_int, y_int, batch_size):\n",
        "            counter+= 1\n",
        "            \n",
        "            # convert numpy arrays to PyTorch arrays\n",
        "            # inputs, targets = torch.tensor(x, dtype=torch.float), torch.tensor(y, dtype=torch.float)\n",
        "            inputs, targets = x, y\n",
        "            \n",
        "            # push tensors to GPU\n",
        "            # inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            # detach hidden states\n",
        "            h = tuple([each.data for each in h])\n",
        "\n",
        "            # zero accumulated gradients\n",
        "            net.zero_grad()\n",
        "            \n",
        "            # get the output from the model\n",
        "            output, h = net(inputs, h)\n",
        "            \n",
        "            # calculate the loss and perform backprop\n",
        "            loss = criterion(output, targets.view(-1))\n",
        "\n",
        "            # back-propagate error\n",
        "            loss.backward()\n",
        "\n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "\n",
        "            # update weigths\n",
        "            opt.step()            \n",
        "            \n",
        "            if counter % print_every == 0:\n",
        "            \n",
        "              print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                    \"Step: {}...\".format(counter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4AJAPUYK5hXK"
      },
      "outputs": [],
      "source": [
        "def get_batches(arr_x, arr_y, batch_size):\n",
        "         \n",
        "    # iterate through the arrays\n",
        "    prv = 0\n",
        "    for n in range(batch_size, arr_x.shape[0], batch_size):\n",
        "      # print(arr_x)\n",
        "      x = arr_x[prv:n]\n",
        "      y = arr_y[prv:n]\n",
        "      prv = n\n",
        "      yield x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_5L9YSI7ZYT"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfYkjf_05m1D"
      },
      "outputs": [],
      "source": [
        "train(net, batch_size = 100, epochs=20, print_every=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbA1aDzy7gXL"
      },
      "source": [
        "## Function to Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsO90utKYZtw"
      },
      "outputs": [],
      "source": [
        "# predict next token\n",
        "def predict(net, tkn, h=None):\n",
        "         \n",
        "  # tensor inputs\n",
        "  x = np.array([[token2int[tkn]]])\n",
        "  inputs = torch.from_numpy(x)\n",
        "  \n",
        "  # push to GPU\n",
        "  inputs = inputs.cuda()\n",
        "\n",
        "  # detach hidden state from history\n",
        "  h = tuple([each.data for each in h])\n",
        "\n",
        "  # get the output of the model\n",
        "  print(inputs, h)\n",
        "  out, h = net(inputs)\n",
        "\n",
        "  # get the token probabilities\n",
        "  p = F.softmax(out, dim=1).data\n",
        "\n",
        "  p = p.cpu()\n",
        "\n",
        "  p = p.numpy()\n",
        "  p = p.reshape(p.shape[1],)\n",
        "\n",
        "  # get indices of top 3 values\n",
        "  top_n_idx = p.argsort()[-3:][::-1]\n",
        "\n",
        "  # randomly select one of the three indices\n",
        "  sampled_token_index = top_n_idx[random.sample([0,1,2],1)[0]]\n",
        "\n",
        "  # return the encoded value of the predicted char and the hidden state\n",
        "  return int2token[sampled_token_index], h\n",
        "\n",
        "\n",
        "# function to generate text\n",
        "def sample(net, size, prime='it is'):\n",
        "        \n",
        "    # push to GPU\n",
        "    # net.cuda()\n",
        "    \n",
        "    net.eval()\n",
        "\n",
        "    # batch size is 1\n",
        "    h = net.init_hidden(1)\n",
        "    \n",
        "    toks = prime.split()\n",
        "\n",
        "    # predict next token\n",
        "    for t in prime.split():\n",
        "      token, h = predict(net, t, h)\n",
        "    \n",
        "    toks.append(token)\n",
        "\n",
        "    # predict subsequent tokens\n",
        "    for i in range(size-1):\n",
        "        token, h = predict(net, toks[-1], h)\n",
        "        toks.append(token)\n",
        "\n",
        "    return ' '.join(toks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo0kU7td7nBN"
      },
      "source": [
        "## Making the Model Predict New Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0nR-DXX6P5C"
      },
      "outputs": [],
      "source": [
        "sample(net, 5, prime = \"amazing product\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Sage_Maker_Text_Generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "5902d8586eb7db257cfd8e277bea4ae0d3d9c427140de5352e4b7e1edb46435b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
